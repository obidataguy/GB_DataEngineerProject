{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c762aef-f1b5-4912-a190-973046137b16",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# CAI BJRY Project - JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7e25be3-76d9-4908-b986-323261decfc2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Initialize Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "314206b5-9b11-4d82-b75c-a787d093eaf8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.widgets.removeAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69f50dd7-a179-4a66-a415-be26958e76c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"input_table\", \"default.cai_bjry__20210309221212\", \" 1. Input Table\")\n",
    "dbutils.widgets.text(\"file_name\", \"cai_bjry__20210309221212\", \" 2. File Name\")\n",
    "dbutils.widgets.text(\"output_schema_name\", \"greenbrier_projects\", \" 3. Output Schema Name\")\n",
    "dbutils.widgets.text(\"output_table_name\", \"movement\", \" 4. Output Table Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d54957d2-93c9-4ebe-8c5b-77401eccd75b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Run Common Functions Notebook\n",
    "This notebook contains functions and libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e5d6583-b1a3-40e6-afbf-0f1a57239bae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./Common Functions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98ea7f9b-84c2-4135-982d-80c0cb29d6ee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Define Notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80a5b779-481d-4f2b-bfaa-10e4caa59e35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "INPUT_TABLE = dbutils.widgets.get(\"input_table\")\n",
    "FILE_NAME = dbutils.widgets.get(\"file_name\")\n",
    "OUTPUT_SCHEMA_NAME = dbutils.widgets.get(\"output_schema_name\")\n",
    "OUTPUT_TABLE_NAME = dbutils.widgets.get(\"output_table_name\")\n",
    "\n",
    "print(f\"INPUT_TABLE             = {INPUT_TABLE}\")\n",
    "print(f\"FILE_NAME               = {FILE_NAME}\")\n",
    "print(f\"OUTPUT_SCHEMA_NAME      = {OUTPUT_SCHEMA_NAME}\")\n",
    "print(f\"OUTPUT_TABLE_NAME       = {OUTPUT_TABLE_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf595fcf-6f2b-4605-8460-8c05b83e0999",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Get current timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70b65775-75fa-46c1-981d-05b8f0da4752",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "df_current_timestamp = spark.createDataFrame([[\"1\"]],[\"id\"])\n",
    "df_current_timestamp = (df_current_timestamp.withColumn(\"currentTimestamp\",current_timestamp()))\n",
    "\n",
    "PROCESSING_TIMESTAMP = df_current_timestamp.select(\"currentTimestamp\").collect()[0][0]\n",
    "print(f\"PROCESSING_TIMESTAMP   = {PROCESSING_TIMESTAMP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e26f0f4-6394-45e1-930f-0ef74b0192ed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Read Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2208287d-b9a3-4921-b451-2741ba20db85",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Read raw json file\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "354c41a9-b85b-49a9-a9c8-614f4c1a41d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# data_json = spark.read.json(path=\"dbfs_file_path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d8dd7f8-ce7a-47bd-8b17-21e8ed50cdd3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Since we don't have access to dbfs we will have to read the data as a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38276c2d-f442-474d-af48-0ccc281f98af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Read raw data as table\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "565d9681-dcbb-406c-a43e-e2cc354ab0b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_raw = spark.table(INPUT_TABLE)\n",
    "## or \n",
    "#data_raw = spark.sql(f\"select * from {INPUT_TABLE}\")\n",
    "display(data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c2c063d-b13b-4253-a521-5adba2c982ac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5637642-e525-4d6e-b786-a56738b876c5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Explode `v1.0.1`\n",
    "- Rename \"v1.0.1\" to \"v1_0_1\"\n",
    "\n",
    "- Explode \"v1_0_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8289092f-08c7-40a8-ae26-4b2416a98f04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## from pyspark.sql.functions import explode\n",
    "\n",
    "explode_v1_0_1 = (data_raw.withColumnRenamed(\"v1.0.1\", \"v1_0_1\")\n",
    "                            .withColumn(\"v1_0_1\", explode(\"v1_0_1\"))\n",
    "                            )\n",
    "display(explode_v1_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f533c86-9cc1-453a-aaae-ca59c3af5fe1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Extract all necesary nested columns in `v1_0_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30a9c1c8-a18c-4f2c-aa9e-3cb34947df0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "expand_equip = explode_v1_0_1.select((input_file_name()).alias(\"input_file_name\"), current_timestamp().alias(\"current_timestamp\")\n",
    "                                     , \"carrier\",\"carrier_id\",\"carrier_timezone\"\n",
    "                                     ,\"event.event_datetime\",\"event.splc\",\"event.report_type\"\n",
    "                                     ,\"v1_0_1.*\")\n",
    "display(expand_equip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "332ca0ea-073f-47df-9fe9-9ceb3fc11170",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Select only needed columns and extract all columns in `interchange` and `waybill`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1008bb32-151e-4904-9161-82701e84f33e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "expand_inter_waybill = expand_equip.select('input_file_name','current_timestamp','carrier','carrier_id','carrier_timezone','event_datetime','splc',\n",
    "                                           'report_type','equipment_initial','equipment_number','interchange.*'\n",
    "                                           ,'load_status','status', 'waybill.*')\n",
    "display(expand_inter_waybill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3394914-337f-4788-a6ec-6b1f8324a5a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Explode `route` and `waybill_parties` with new column names `routes` and `waybills`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8750672-f1c7-4561-a824-de2ff8050b0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "explode_routes_waybill = (expand_inter_waybill.withColumn(\"route\", explode(\"route\"))\n",
    "           .withColumn(\"waybill_parties\", explode(\"waybill_parties\"))\n",
    "           )\n",
    "display(explode_routes_waybill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c38efcd1-8e38-460c-9447-b9b58b52c66b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Select columns needed for Movement table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a26a46c-bbfd-4316-98ae-d79f834aee5d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_movement = explode_routes_waybill.select('input_file_name','current_timestamp','carrier','carrier_timezone','equipment_initial','equipment_number' \n",
    "                                            ,'report_type','load_status' ,'train_id','event_datetime','splc','from_carrier_code','interchange_timestamp'\n",
    "                                            ,'to_carrier_code','shipment_qualifier','waybill_number').distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "508ba2bc-874f-4e43-9c87-75ff4146befd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Remove leading and trailing spaces from all columns except `train_id`\n",
    "\n",
    "Load function `remove_leading_trailing_spaces` from `Common Functions` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3dfe72c-d376-4b1c-b951-01f1eefe7bd0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_trim = remove_leading_trailing_spaces(df_movement, 'train_id')\n",
    "display(df_trim.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f5ca954-dac3-4032-8249-18040fc92257",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Add source file name, select and rename required columns\n",
    "1. Extract only file name from column `input_file_name` and rename to `FileName` \n",
    "2. Adjust `event_datetime` for time zone based on the `carrier_timezone`\n",
    "3. Get `WaybillId` column\n",
    "4. Select required columns and rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0aaf4d1b-e76e-48e8-82b1-05938188e2cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import lit, substring, from_utc_timestamp, concat\n",
    "# from pyspark.sql.types import DateType, IntegerType, TimestampType\n",
    "\n",
    "transform_columns = (df_trim.withColumn(\"input_file_name\",(substring(\"input_file_name\",24,27))) # or use lit(f\"{FILE_NAME}\")) \n",
    "                            .withColumn(\"event_datetime_adjusted\", from_utc_timestamp(col(\"event_datetime\"), col(\"carrier_timezone\"))) \n",
    "                            .withColumn(\"WaybillId\", concat(col(\"carrier\"),col(\"waybill_number\"),col(\"interchange_timestamp\")))\n",
    "                            .select(col(\"input_file_name\").alias(\"FileName\") \n",
    "                                   ,col(\"current_timestamp\").alias(\"ProcessDatetime\").cast(TimestampType())\n",
    "                                   ,col(\"equipment_initial\").alias(\"EquipmentInitial\") \n",
    "                                   ,col(\"equipment_number\").alias(\"EquipmentNumber\").cast(IntegerType())\n",
    "                                   ,col(\"report_type\").alias(\"ReportType\")\n",
    "                                   ,col(\"carrier\").alias(\"ReportingRoad\")\n",
    "                                   ,col(\"load_status\").alias(\"LoadStatus\")\n",
    "                                   ,col(\"train_id\").alias(\"TrainID\")\n",
    "                                   ,col(\"event_datetime_adjusted\").alias(\"EventDate\").cast(DateType())\n",
    "                                   ,col(\"event_datetime_adjusted\").alias(\"EventDatetime\").cast(TimestampType())\n",
    "                                   ,col(\"splc\").alias(\"SPLC\").cast(IntegerType())\n",
    "                                   ,col(\"from_carrier_code\").alias(\"FromRoad\")\n",
    "                                   ,col(\"to_carrier_code\").alias(\"ToRoad\")\n",
    "                                   ,col(\"WaybillId\")\n",
    "                                   ,col(\"shipment_qualifier\").alias(\"JointServiceCode\")\n",
    "                                                )\n",
    "                     )\n",
    "display(transform_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1d491fc-7a86-464b-8698-31e82fed6b57",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## FromRoad and ToRoad\n",
    "Populate FromRoad and ToRoad if report_type (ReportType) is either 'ICHD' or 'ICHR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2261ef26-a892-4d56-b792-a1cea8a1a229",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## from pyspark.sql.functions import when\n",
    "transform_columns = (transform_columns.withColumn(\"FromRoad\", when(transform_columns.ReportType == 'ICHD',transform_columns.FromRoad)\n",
    "                                                              .when(transform_columns.ReportType == 'ICHR',transform_columns.FromRoad)\n",
    "                                                              .otherwise(None))\n",
    "                                      .withColumn(\"ToRoad\", when(transform_columns.ReportType == 'ICHD',transform_columns.ToRoad)\n",
    "                                                              .when(transform_columns.ReportType == 'ICHR',transform_columns.ToRoad)\n",
    "                                                              .otherwise(None))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46d7de93-14ae-4419-add1-9b17ecd6a966",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transform_columns.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "045ea1f6-9afc-456e-a3a2-30cfc796130b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Note: The mapping for `City`, `State`, `WaybillVersion` and `ClientEventCode` are missing from the json\n",
    "\n",
    "\n",
    "To get `City` and `State` I would join the splc table to the movement table on SPLC merging only City and State.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad39dc12-4c32-4599-b41b-07bd5d2579eb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## DQ Check - Schema and data types\n",
    "Run some checks on our columns and dtypes to match sure they meet requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27ca4140-40b9-476c-a718-67a30d524416",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assert transform_columns.columns == ['FileName','ProcessDatetime','EquipmentInitial','EquipmentNumber','ReportType','ReportingRoad'\n",
    "                                     ,'LoadStatus','TrainID','EventDate','EventDatetime','SPLC','FromRoad','ToRoad'\n",
    "                                     ,'WaybillId','JointServiceCode']\n",
    "assert transform_columns.dtypes == [('FileName', 'string'),('ProcessDatetime', 'timestamp'),('EquipmentInitial', 'string')\n",
    "                                     ,('EquipmentNumber', 'int'),('ReportType', 'string'),('ReportingRoad', 'string')\n",
    "                                     ,('LoadStatus', 'string'),('TrainID', 'string'),('EventDate', 'date'), ('EventDatetime', 'timestamp')\n",
    "                                     ,('SPLC', 'int'),('FromRoad', 'string'),('ToRoad', 'string'),('WaybillId', 'string')\n",
    "                                     ,('JointServiceCode', 'string')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dfca1e8-5b53-4fff-a006-deaa7a815896",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Write to Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b601b70-0425-4570-bde6-fb2427ebcc74",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create Schema `greenbrier_projects`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7e25af0-dde5-4545-a077-f6d5bdd181c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create schema if not exists ${output_schema_name};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a0bf262-6de2-4918-a63d-54295db15389",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--drop schema ${output_schema_name};\n",
    "--drop table ${output_schema_name}.${output_table_name};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beb2f9a6-850b-4732-98ac-d0756a8c7b29",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create Temp view `movement_vw` from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f217aca4-357d-41dd-beea-9e399821d3fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temp_view = transform_columns.createOrReplaceTempView(\"movement_vw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f12d539-ae1a-4b32-a232-facde4fc1c6c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Use *INSERT INTO* to add records to `movenment` delta table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6713358b-f055-47d7-84fc-0845796a5b8f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create table and insert data using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35da8b34-f3be-4c10-be98-41c255dba6c4",
     "showTitle": true,
     "title": "USe SQL"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create or replace table ${output_schema_name}.${output_table_name} (FileName\t\t                    string,\n",
    "                                                                    ProcessDatetime\t                timestamp,\n",
    "                                                                    EquipmentInitial\t              string, \n",
    "                                                                    EquipmentNumber\t\t              int not null,\n",
    "                                                                    ReportType                      string,\n",
    "                                                                    ReportingRoad\t\t                string,\n",
    "                                                                    LoadStatus\t\t                  string,\n",
    "                                                                    TrainID\t\t\t                    string,\n",
    "                                                                    EventDate\t\t                    date,\n",
    "                                                                    EventDatetime\t\t                timestamp,\n",
    "                                                                    SPLC                            int,\n",
    "                                                                    FromRoad                        string,\n",
    "                                                                    ToRoad                          string,\n",
    "                                                                    WaybillId                       string,\n",
    "                                                                    JointServiceCode                string);\n",
    "                                                                    \n",
    "insert into ${output_schema_name}.${output_table_name}\n",
    "select * from movement_vw;   -- select all from the temporary view movement_vw\n",
    "\n",
    "select * from ${output_schema_name}.${output_table_name};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a654185e-a0f5-423e-bf13-433fc5548c7b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create table and insert data using pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b45ac64-e1a2-43bf-97f8-295253f397e6",
     "showTitle": true,
     "title": "Create schema and table using pyspark"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"create or replace table {OUTPUT_SCHEMA_NAME}.{OUTPUT_TABLE_NAME} (FileName\t\t          string,\n",
    "                                                                                  ProcessDatetime\t      timestamp,\n",
    "                                                                                  EquipmentInitial\t      string,\n",
    "                                                                                  EquipmentNumber\t\t  int not null,\n",
    "                                                                                  ReportType              string,\n",
    "                                                                                  ReportingRoad\t\t      string,\n",
    "                                                                                  LoadStatus\t\t      string,\n",
    "                                                                                  TrainID\t\t\t      string,\n",
    "                                                                                  EventDate\t\t          date,\n",
    "                                                                                  EventDatetime\t\t      timestamp,\n",
    "                                                                                  SPLC                    int,\n",
    "                                                                                  FromRoad                string,\n",
    "                                                                                  ToRoad                  string,\n",
    "                                                                                  WaybillId               string,\n",
    "                                                                                  JointServiceCode        string);\n",
    "          \"\"\")                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa21eada-2f85-4b7c-8f74-282d3aa3c09c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "          insert into {OUTPUT_SCHEMA_NAME}.{OUTPUT_TABLE_NAME}\n",
    "          select * from movement_vw   -- select all from the temporary view movement_vw\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5deff805-4945-40d3-977b-0ad3e3842553",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Use CTAS to create table to `movement` delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edef255c-87f2-4340-bdf3-f867d2356c59",
     "showTitle": true,
     "title": "Using SQL"
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# use greenbrier_projects; -- use schema greenbrier_projects\n",
    "# create or replace table movement\n",
    "# as\n",
    "# select * from movement_vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51ba1303-73c1-4d2c-95f3-2fd1caa71e07",
     "showTitle": true,
     "title": "Using Pyspark"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\" \n",
    "          create or replace table {OUTPUT_SCHEMA_NAME}.{OUTPUT_TABLE_NAME}\n",
    "          as\n",
    "          select * from movement_vw -- select all from the temporary view movement_vw\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8505d09-7f6d-4c93-b7c8-b6b93ad6361a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(f\"select * from {OUTPUT_SCHEMA_NAME}.{OUTPUT_TABLE_NAME}\")\n",
    "df.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3563193120348293,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Greenbrier Project 01 - CAI_BJRY",
   "widgets": {
    "file_name": {
     "currentValue": "cai_bjry__20210309221212",
     "nuid": "80e79ef3-a9ca-4970-815b-4b3e060d6d76",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "defaultValue": "cai_bjry__20210309221212",
      "label": " 2. File Name",
      "name": "file_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "input_table": {
     "currentValue": "default.cai_bjry__20210309221212",
     "nuid": "5a054cc2-577c-48d7-9e5e-89cd601c0a57",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "defaultValue": "default.cai_bjry__20210309221212",
      "label": " 1. Input Table",
      "name": "input_table",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "output_schema_name": {
     "currentValue": "greenbrier_projects",
     "nuid": "bd18ecf2-5627-45ab-91ea-40743d9cc251",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "defaultValue": "greenbrier_projects",
      "label": " 3. Output Schema Name",
      "name": "output_schema_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "output_table_name": {
     "currentValue": "movement",
     "nuid": "abb3c945-4ad4-4d1e-a8e4-413e6e9309e2",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "defaultValue": "movement",
      "label": " 4. Output Table Name",
      "name": "output_table_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "LLM_Python_3_11_7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
